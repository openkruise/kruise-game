name: E2E-1.30

on:
  push:
    branches:
      - master
      - release-*
  pull_request: {}
  workflow_dispatch: {}

env:
  # Common versions
  GO_VERSION: '1.22'
  KIND_VERSION: 'v0.22.0'
  KIND_IMAGE: 'kindest/node:v1.30.8'
  KIND_CLUSTER_NAME: 'ci-testing'
  CERT_MANAGER_VERSION: 'v1.18.2'

jobs:

  game-kruise:
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v3
        with:
          submodules: true
      - name: Setup Go
        uses: actions/setup-go@v3
        with:
          go-version: ${{ env.GO_VERSION }}
        # Prepare audit policy before cluster creation so extraMounts can find it
      - name: Prepare audit policy
        run: |
          mkdir -p /tmp/kind-audit
          cp test/audit/policy.yaml /tmp/kind-audit/policy.yaml
      - name: Setup Kind Cluster
        uses: helm/kind-action@v1.12.0
        with:
          node_image: ${{ env.KIND_IMAGE }}
          cluster_name: ${{ env.KIND_CLUSTER_NAME }}
          config: ./test/kind-conf.yaml
          version: ${{ env.KIND_VERSION }}
      - name: Ensure audit log file exists and is world-readable
        run: |
          sudo mkdir -p /tmp/kind-audit
          sudo touch /tmp/kind-audit/audit.log
          sudo chmod 0644 /tmp/kind-audit/audit.log
      - name: Build image
        run: |
          export IMAGE="openkruise/kruise-game-manager:e2e-${GITHUB_RUN_ID}"
          docker build --pull --no-cache . -t $IMAGE
          kind load docker-image --name=${KIND_CLUSTER_NAME} $IMAGE || { echo >&2 "kind not installed or error loading image: $IMAGE"; exit 1; }
      - name: Install Cert-Manager
        run: |
          kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/${{ env.CERT_MANAGER_VERSION }}/cert-manager.yaml
          kubectl -n cert-manager rollout status deploy/cert-manager-webhook --timeout=180s
      - name: Install Kruise
        run: |
          set -ex
          kubectl cluster-info
          make helm
          helm repo add openkruise https://openkruise.github.io/charts/ || true
          helm repo update
          helm install kruise openkruise/kruise --version 1.8.0
          for ((i=1;i<10;i++));
          do
            set +e
            PODS=$(kubectl get pod -n kruise-system | grep '1/1' | grep kruise-controller-manager | wc -l)
            set -e
            if [ "$PODS" -eq "2" ]; then
              break
            fi
            sleep 3
          done
          set +e
          PODS=$(kubectl get pod -n kruise-system | grep '1/1' | grep kruise-controller-manager | wc -l)
          set -e
          if [ "$PODS" -eq "2" ]; then
            echo "Wait for kruise-manager ready successfully"
          else
            echo "Timeout to wait for kruise-manager ready"
            exit 1
          fi
      - name: Install Kruise Game in HA mode
        run: |
          set -ex
          IMG=openkruise/kruise-game-manager:e2e-${GITHUB_RUN_ID} ENABLE_HA=true ./scripts/deploy_kind.sh
          
          # Wait for the controller manager to be ready at least 1 replica
          for i in {1..30}; do
            set +e
            PODS=$(kubectl get pod -n kruise-game-system | grep '1/1' | wc -l)
            set -e
            if [ "$PODS" -eq "1" ]; then
              break
            fi
            echo "Waiting for controller ready... ($i/10)"
            sleep 3
          done

          # Verify that at least 2 controller replicas are running
          PODS=$(kubectl get pod -n kruise-game-system --selector=control-plane=controller-manager -o jsonpath='{.items..metadata.name}' | wc -w)
          if [ "$PODS" -lt "2" ]; then
            echo "HA mode requires at least 2 controller replicas, but found $PODS"
            kubectl get pod -n kruise-game-system
            exit 1
          fi
          echo "Kruise Game installed in HA mode successfully"
      - name: Verify Kind Cluster
        run: |
          set -euo pipefail
          echo "=== Verifying Kind cluster ==="
          kind get clusters
          kubectl config use-context kind-${KIND_CLUSTER_NAME}
          kubectl cluster-info --request-timeout=15s
          kubectl get nodes
      - name: Run E2E Tests before failover
        run: |
          echo "=== Switching to Kind context ==="
          kubectl config use-context kind-${KIND_CLUSTER_NAME}
          
          echo "=== Verifying current context ==="
          kubectl config current-context
          
          echo "=== Checking cluster status ==="
          kubectl cluster-info
          kubectl get nodes
          
          echo "=== Building ginkgo ==="
          make ginkgo
          
          echo "=== Running tests with verbose output ==="
          ./bin/ginkgo --timeout 10m -v --trace --progress test/e2e || EXIT_CODE=$?
          
          echo "=== Collecting diagnostics ==="
          kubectl get gss -A
          kubectl get pods -n e2e-test
          kubectl get events -n e2e-test
          
          exit ${EXIT_CODE:-0}
      - name: Test HA Failover
        run: |
          set -e
          NAMESPACE=kruise-game-system
          LEASE_NAME=game-kruise-manager
          echo "--- Identifying initial leader ---"
          LEADER_POD=$(kubectl get lease $LEASE_NAME -n $NAMESPACE -o jsonpath='{.spec.holderIdentity}' | awk -F'_' '{print $1}')
          if [ -z "$LEADER_POD" ]; then
            echo "Could not determine leader pod."
            exit 1
          fi
          echo "Current leader is $LEADER_POD"

          echo "--- Deleting leader pod to trigger failover ---"
          kubectl delete pod $LEADER_POD -n $NAMESPACE
          
          echo "--- Waiting for new leader to be elected ---"
          for i in {1..30}; do
            NEW_LEADER_POD=$(kubectl get lease $LEASE_NAME -n $NAMESPACE -o jsonpath='{.spec.holderIdentity}' | awk -F'_' '{print $1}')
            if [ -n "$NEW_LEADER_POD" ] && [ "$NEW_LEADER_POD" != "$LEADER_POD" ]; then
              echo "New leader elected: $NEW_LEADER_POD"
              break
            fi
            echo "Waiting for new leader... ($i/30)"
            sleep 5
          done

          if [ "$NEW_LEADER_POD" == "$LEADER_POD" ] || [ -z "$NEW_LEADER_POD" ]; then
            echo "Failover failed. A new leader was not elected in time."
            kubectl get lease $LEASE_NAME -n $NAMESPACE -o yaml
            exit 1
          fi

          echo "--- Verifying all controller pods are ready after failover ---"
          # Wait for the controller manager to be ready at least 1 replica
          for i in {1..30}; do
            set +e
            PODS=$(kubectl get pod -n kruise-game-system | grep '1/1' | wc -l)
            set -e
            if [ "$PODS" -eq "1" ]; then
              break
            fi
            echo "Waiting for controller ready... ($i/10)"
            sleep 3
          done
          echo "HA Failover successful."
      - name: Run E2E Tests after failover
        run: |
          export KUBECONFIG=/home/runner/.kube/config
          ./bin/ginkgo --timeout 10m -v test/e2e
          retVal=$?
          restartCount=$(kubectl get pod -n kruise-game-system --no-headers | awk '{print $4}' | awk '{s+=$1} END {print s}')
          if [ "${restartCount}" -le "1" ];then # Allow for 1 restart from the deleted leader
              echo "Kruise-game has not restarted unexpectedly"
          else
              echo "Kruise-game has restarted unexpectedly, abort!!!"
              kubectl get pod -n kruise-game-system
              kubectl get pod -n kruise-game-system --no-headers | awk '{print $1}' | xargs -I {} kubectl logs {} -p -n kruise-game-system --tail=100
              exit 1
          fi
          exit $retVal
      - name: Make audit logs readable
        if: always()
        run: |
          sudo chmod -R a+r /tmp/kind-audit || true
          ls -l /tmp/kind-audit || true
      - name: Upload audit logs artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: kind-audit-logs-1.30
          path: /tmp/kind-audit
          if-no-files-found: ignore
